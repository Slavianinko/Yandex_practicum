# Классификация токсичных комментариев

Статус проекта: | В плане :black_square_button: | Выполняется :black_square_button: | Завершён :white_check_mark: | 
:------------ | :-------------| :-------------| :-------------

## Задача:

Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию.

Необходимо обучить модель классификации комментариев на позитивные и негативные. В нашем распоряжении набор данных с разметкой о токсичности правок.

Необходимо построить модель со значением метрики качества F1 не меньше 0.75.

## Данные:

Столбец text в нём содержит текст комментария, а toxic — целевой признак.


## Используемые библиотеки
- pandas
- numpy
- matplotlib
- nltk
- scipy
- sklearn
- CatBoost
- torch
- transformers
- wordcloud 

## Отработанные методы и навыки
- Исследовательский анализ текстовых данных;
- Преобразование текстовых данных: очистка, лематизация, векторизация TF-IDF;
- Построение моделей машинного обучения для классификации текста:
  - Линейная регрессия;
  - Решающее дерево;
  - CatBoostRegressor;
- Использование модели BERT для классификации текстов.

## Итоги проекта

1. Если требуется высокое качество классификации, то необходимо преобразовывать текстовые данные с помощью модели BERT. За это мы расплатимся более высокими требованиями к вычислительным мощьностям.
2. Если можно обойтись немного меньшим качеством классификации, либо мы не располагаем необходимыми вычислительными мощьностяим, то можно применить менее требовательный к железу способ преобразования текста TF-IDF и модель классификации Логистическая регрессия.

