{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Классификация одежды.","metadata":{}},{"cell_type":"markdown","source":"Необходимо построить модель, которая по фотографии определит тип предмета гардероба. В нашем распоряжении набор фотографий вещей из датасета [Fashion MNIST](https://www.kaggle.com/datasets/zalando-research/fashionmnist).\n\nПоследовательность решения задачи:\n1. Анализ данных;\n2. Подготовка данных;\n3. Создание модели и её обучение;\n4. Вывод и оценка качества модели.","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom PIL import Image\n\nfrom tensorflow.keras.datasets import fashion_mnist\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, Flatten, Dense, AvgPool2D\nfrom tensorflow.keras.optimizers import Adam, Adamax\nfrom tensorflow.keras.applications.resnet import ResNet50","metadata":{"execution":{"iopub.status.busy":"2022-07-16T16:09:23.358279Z","iopub.execute_input":"2022-07-16T16:09:23.358765Z","iopub.status.idle":"2022-07-16T16:09:25.809687Z","shell.execute_reply.started":"2022-07-16T16:09:23.358666Z","shell.execute_reply":"2022-07-16T16:09:25.808571Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"PATH = '/kaggle/input/fashionmnist/'","metadata":{"execution":{"iopub.status.busy":"2022-07-16T16:09:25.811902Z","iopub.execute_input":"2022-07-16T16:09:25.813178Z","iopub.status.idle":"2022-07-16T16:09:25.820284Z","shell.execute_reply.started":"2022-07-16T16:09:25.813105Z","shell.execute_reply":"2022-07-16T16:09:25.818670Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Анализ данных\n\nЗагрузим и проанализируем данные.","metadata":{}},{"cell_type":"code","source":"# Загрузка данных\ndf_train = pd.read_csv(PATH + 'fashion-mnist_train.csv')\ndf_test = pd.read_csv(PATH + 'fashion-mnist_test.csv')","metadata":{"execution":{"iopub.status.busy":"2022-07-16T16:09:25.822253Z","iopub.execute_input":"2022-07-16T16:09:25.822988Z","iopub.status.idle":"2022-07-16T16:09:31.951139Z","shell.execute_reply.started":"2022-07-16T16:09:25.822942Z","shell.execute_reply":"2022-07-16T16:09:31.949773Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def data_info(df):\n    \"\"\"Изучение датасета\"\"\"\n    display(df.head())\n    display(df.info())\n    # Проверка дизбаланса классов\n    df['label'].hist()\n    print('Количество дубликатов =', df.duplicated().sum())\n    ","metadata":{"execution":{"iopub.status.busy":"2022-07-16T16:09:31.955416Z","iopub.execute_input":"2022-07-16T16:09:31.956321Z","iopub.status.idle":"2022-07-16T16:09:31.962694Z","shell.execute_reply.started":"2022-07-16T16:09:31.956269Z","shell.execute_reply":"2022-07-16T16:09:31.961414Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Анализ трениоровочных данных\ndata_info(df_train)","metadata":{"execution":{"iopub.status.busy":"2022-07-16T16:09:31.964009Z","iopub.execute_input":"2022-07-16T16:09:31.964698Z","iopub.status.idle":"2022-07-16T16:09:33.493848Z","shell.execute_reply.started":"2022-07-16T16:09:31.964655Z","shell.execute_reply":"2022-07-16T16:09:33.492372Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Анализ тестовых данных\ndata_info(df_test)","metadata":{"execution":{"iopub.status.busy":"2022-07-16T16:09:33.496202Z","iopub.execute_input":"2022-07-16T16:09:33.497502Z","iopub.status.idle":"2022-07-16T16:09:33.953402Z","shell.execute_reply.started":"2022-07-16T16:09:33.497447Z","shell.execute_reply":"2022-07-16T16:09:33.952192Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Надвания классов вещей\nclass_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', \n               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']","metadata":{"execution":{"iopub.status.busy":"2022-07-16T16:09:33.955041Z","iopub.execute_input":"2022-07-16T16:09:33.955895Z","iopub.status.idle":"2022-07-16T16:09:33.963073Z","shell.execute_reply.started":"2022-07-16T16:09:33.955842Z","shell.execute_reply":"2022-07-16T16:09:33.961255Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Выделим по одному изображению каждого класса\none_category = df_train.groupby('label').head(1)\none_category = one_category.set_index('label')\n\n# Вывод на экран изображений\nfig, axes = plt.subplots(nrows=1, ncols=10, figsize=(20,7))\n\nn = 0\nfor ax in axes.flat:\n    ax.set(title=(class_names[n]))\n    image = one_category.loc[n,:].values.reshape(28, 28, 1)\n    ax.imshow(image, cmap=plt.cm.binary)\n    n += 1\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-16T16:09:33.964583Z","iopub.execute_input":"2022-07-16T16:09:33.964958Z","iopub.status.idle":"2022-07-16T16:09:34.861742Z","shell.execute_reply.started":"2022-07-16T16:09:33.964925Z","shell.execute_reply":"2022-07-16T16:09:34.860142Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"**Вывод**\n\n1. Набор данных содержит 60000 изображений в тренировочном наборе и 10000 изображений в тестовом наборе данных. Такого количества должно быть достаточно для обучения модели.\n2. Вещи предствалены 10 классов, причём их количество по классам одинаково. Таким образом, дизбаланса классов не наблюдается.\n3. Изображеняи имеют размер 28Х28 пиксклей и один канал цвета. В датасети они представлены в виде списка, поэтому на этапе предобработки, их необходимо привести в двумерный вид.\n4. Изображения предобработаны, и не требуют дальнейшего преобразования.\n5. В тренировочном наборе данных присутствует 43 дубликата. В целом, такое небольшое количество повторяющехся изображений не должно сильно сказаться на качестве обучения модели, думаю лучше будет от них избавится.\n","metadata":{}},{"cell_type":"markdown","source":"## Подготовка данных и обучение модели","metadata":{}},{"cell_type":"markdown","source":"1. Избавимся от дубликатов.\n2. Создадим функции `load_train` и `load_test` по подготовке данных тренировочного и тестового набора данных. В них произведём преобразование данных из одномерного списка в двумерное изображение и нормализуем их.\n3. Создадим функцию `create_model_LeNet`, которая будет создавать и компилировать модель. Применим нейросетевую модель с архитектурой LeNet. Оптимизатор и его параметры выберем опытным путём.\n4. Создадим функцию `train_model`, которая будет отвечать за обучение модели.\n5. Обучим модель.","metadata":{}},{"cell_type":"code","source":"# Удалим дубликаты\ndf_train = df_train.drop_duplicates()","metadata":{"execution":{"iopub.status.busy":"2022-07-16T16:09:34.866083Z","iopub.execute_input":"2022-07-16T16:09:34.866463Z","iopub.status.idle":"2022-07-16T16:09:36.135597Z","shell.execute_reply.started":"2022-07-16T16:09:34.866434Z","shell.execute_reply":"2022-07-16T16:09:36.133831Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def load_train(df_train):\n    \"\"\" Принимаем датафрейм с тренировочными данными.\n        Возвращаем преобразованные и нормализованные признаки и целевой признак\n    \"\"\"\n    features_train = df_train.drop('label', axis=1).values\n    target_train = df_train['label']\n    features_train = features_train.reshape(-1, 28, 28, 1) / 255.0\n    return features_train, target_train","metadata":{"execution":{"iopub.status.busy":"2022-07-16T16:09:36.137740Z","iopub.execute_input":"2022-07-16T16:09:36.138168Z","iopub.status.idle":"2022-07-16T16:09:36.145863Z","shell.execute_reply.started":"2022-07-16T16:09:36.138113Z","shell.execute_reply":"2022-07-16T16:09:36.144538Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def load_test(df_test):\n    \"\"\" Принимаем датафрейм с тестовыми данными.\n        Возвращаем преобразованные и нормализованные признаки и целевой признак\n    \"\"\"\n    features_test = df_test.drop('label', axis=1).values\n    target_test = df_test['label']\n    features_test = features_test.reshape(-1, 28, 28, 1) / 255.0\n    return features_test, target_test","metadata":{"execution":{"iopub.status.busy":"2022-07-16T16:09:36.147663Z","iopub.execute_input":"2022-07-16T16:09:36.148061Z","iopub.status.idle":"2022-07-16T16:09:36.160899Z","shell.execute_reply.started":"2022-07-16T16:09:36.148029Z","shell.execute_reply":"2022-07-16T16:09:36.159680Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def create_model(input_shape, optimizer=Adam(learning_rate=0.001)):\n    \"\"\" Принимаем размер входных данных и оптимизатор.\n        Возвращаем созданную модель\n    \"\"\"\n    model = Sequential()\n    model.add(Conv2D(kernel_size=(5, 5), filters=6, padding='same', activation='relu', input_shape=input_shape))\n    model.add(AvgPool2D(pool_size=(2, 2)))\n    model.add(Conv2D(kernel_size=(5, 5), filters=16, padding='valid', activation='relu', strides=1))\n    model.add(AvgPool2D(pool_size=(2, 2)))\n    model.add(Flatten())\n    model.add(Dense(units=120, activation='relu'))\n    model.add(Dense(units=84, activation='relu'))\n    model.add(Dense(units=10, activation='softmax'))\n   \n    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy',\n                  metrics=['acc'])\n    model.summary()\n    \n    return model\n","metadata":{"execution":{"iopub.status.busy":"2022-07-16T16:09:36.162758Z","iopub.execute_input":"2022-07-16T16:09:36.163251Z","iopub.status.idle":"2022-07-16T16:09:36.174083Z","shell.execute_reply.started":"2022-07-16T16:09:36.163198Z","shell.execute_reply":"2022-07-16T16:09:36.172670Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def train_model(model, train_data, test_data, batch_size=32, epochs=10,\n               steps_per_epoch=None, validation_steps=None):\n    \"\"\" Принимаем модель, данные и параметры.\n        Возвращаем обученную модель\n    \"\"\"\n    features_train, target_train = train_data\n    features_test, target_test = test_data\n    model.fit(features_train, target_train, \n              validation_data=(features_test, target_test),\n              batch_size=batch_size, epochs=epochs,\n              steps_per_epoch=steps_per_epoch,\n              validation_steps=validation_steps,\n              verbose=2, shuffle=True)\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-07-16T16:09:36.178960Z","iopub.execute_input":"2022-07-16T16:09:36.180690Z","iopub.status.idle":"2022-07-16T16:09:36.188759Z","shell.execute_reply.started":"2022-07-16T16:09:36.180627Z","shell.execute_reply":"2022-07-16T16:09:36.187829Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# Обучение модели\nmodel = train_model(create_model((28, 28, 1), optimizer=Adamax(learning_rate=0.007)), \n                    load_train(df_train),\n                    load_test(df_test),\n                    batch_size=64,\n                    epochs=10,\n                   )","metadata":{"execution":{"iopub.status.busy":"2022-07-16T16:09:56.969235Z","iopub.execute_input":"2022-07-16T16:09:56.969879Z","iopub.status.idle":"2022-07-16T16:11:18.936362Z","shell.execute_reply.started":"2022-07-16T16:09:56.969822Z","shell.execute_reply":"2022-07-16T16:11:18.934930Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# Визуализация процесса обучения модели\nfig = plt.figure(figsize=(15,5))\n\nax_1 = fig.add_subplot(1, 2, 1)\nax_1.set_title('Accuracy', fontsize=16)\nax_1.set_xlabel('Epoch Number', fontsize=14)\nax_1.set_ylabel('accuracy', fontsize=14)\nax_1 = plt.plot(model.history.history['acc'], label='training set')\nax_1 = plt.plot(model.history.history['val_acc'], label='testing set')\nplt.legend();\n\n# \nax_2 = fig.add_subplot(1, 2, 2)\nax_2.set_title('Loos function', fontsize=16)\nax_2.set_xlabel('Epoch Number', fontsize=14)\nax_2.set_ylabel('sparse_categorical_crossentropy', fontsize=14)\nax_2 = plt.plot(model.history.history['loss'], label='training set')\nax_2 = plt.plot(model.history.history['val_loss'], label='testing set')\n\n\nplt.legend();","metadata":{"execution":{"iopub.status.busy":"2022-07-16T16:11:18.939160Z","iopub.execute_input":"2022-07-16T16:11:18.940099Z","iopub.status.idle":"2022-07-16T16:11:19.306614Z","shell.execute_reply.started":"2022-07-16T16:11:18.940058Z","shell.execute_reply":"2022-07-16T16:11:19.305200Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"**Вывод**\n\nБыла поставлена задача классификации предметов гардероба по изображению.\n\nАнализ данных выявил, что больших проблем, влияющих на возможность построения модели в наборе данных нет. Были удалены дубликаты, данные были приведены к двумерному виду и нормализованы.\n\nЗатем была создана модель на основе нейросетевой архитектуры LeNet, отличающейся от оригинальной тем, что активаторы были заменены на 'relu'. \n\nМодель показала точность классификации = 0.91.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}